{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a762858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torchvision as tv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac72098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tv.datasets.MNIST(root='.', download=True)\n",
    "ds_test = tv.datasets.MNIST(root='.', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1aeeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_x_train = np.array([np.array(x[0]) for x in ds_train])\n",
    "np_x_test = np.array([np.array(x[0]) for x in ds_test])\n",
    "np_x_train = np_x_train / 255.\n",
    "np_x_test = np_x_test / 255.\n",
    "\n",
    "# re-prep the datasets\n",
    "ds_train = th.utils.data.TensorDataset(th.tensor(np_x_train.reshape(-1,28*28), device=th.device('cuda'), dtype=th.float32))\n",
    "ds_test = th.utils.data.TensorDataset(th.tensor(np_x_test.reshape(-1,28*28), device=th.device('cuda'), dtype=th.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c9124f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "dl = th.utils.data.DataLoader(ds_train, batch_size=BATCH_SIZE)\n",
    "for x, in dl:\n",
    "    break\n",
    "plt.matshow(x[0].cpu().numpy().reshape(28,28))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e98a6e",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Gradient Tree Boosting Algorithm}}$<br>\n",
    "***\n",
    "$$f_{0}(x) = \\textrm{arg min}_{\\gamma} \\sum \\limits _{i=1} ^{N} L(y_{i}, \\gamma)$$\n",
    "\n",
    "1.&emsp;Initialize model with a constant value $$f_{0}(x) = \\textrm{arg min}_{\\gamma} \\sum \\limits _{i=1} ^{N} L(y_{i}, \\gamma)$$\n",
    "2.&emsp;For m = 1 to M:<br>\n",
    "&emsp;&emsp;(a)&emsp;For $i = 1,2,...,N$ compute<br>\n",
    "    $$r_{im} = - \\displaystyle \\Bigg[\\frac{\\partial L(y_{i}, f(x_{i}))}{\\partial f(x_{i})}\\Bigg]_{f=f_{m−1}}$$\n",
    "&emsp;&emsp;(b)&emsp;Fit a regression tree to the targets $r_{im}$ giving terminal regions<br>\n",
    "&emsp;&emsp;&emsp;&emsp;$R_{jm}, j = 1, 2, . . . , J_{m}.$<br><br>\n",
    "&emsp;&emsp;(c)&emsp;For $j = 1, 2, . . . , J_{m}$ compute<br>\n",
    "$$\\gamma_{jm} = \\underset{\\gamma}{\\textrm{arg min}} \\sum \\limits _{x_{i} \\in R_{jm}} L(y_{i}, f_{m−1}(x_{i}) + \\gamma)$$\n",
    "<br>\n",
    "&emsp;&emsp;(d)&emsp;Update $f_{m}(x) = f_{m−1}(x) + \\sum _{j=1} ^{J_{m}} \\gamma_{jm} I(x \\in R_{jm})$<br><br>\n",
    "3. Output $\\hat{f}(x) = f_{M}(x)$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee19f1b0",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{KL Reminder}}$<br>\n",
    "***\n",
    "$$KL = \\textrm{arg min}_{\\gamma} \\sum \\limits _{i=1} ^{N} L(y_{i}, \\gamma)$$\n",
    "$$KL(D_1,D_2) = \\log (\\frac{s_2}{s_1}) + \\frac {1}{2} \\frac {s_1^2 +(m_1 - m_2)^2} {s_2^2} - \\frac{1}{2}$$\n",
    "\n",
    "\n",
    "      if target is N(0,1) then s2 = 1 m2 = 0 then\n",
    "       KL_Loss = 0 - log(s1) + 0.5 * (s1**2 + m1**2) - 0.5\n",
    "       KL_loss = -0.5 * ( 2*log(s1) - s1**2 - m1**2 + 1)\n",
    "       or when targeting the std instead of variance\n",
    "       KL_loss = -0.5 * (log(s1) - s1 - m1**2 + 1)\n",
    "         in this case z = rnd * s1 + m1\n",
    "       or (targeting log_of_s1)\n",
    "       KL_loss = -0.5 * (s1_ln - e**s1_ln - m1**2 + 1)\n",
    "         in this case the z = rnd * e**(s1_ln/2) + m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45047829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVAE(th.nn.Module):\n",
    "    def __init__(self, inp_size, encoding=[512, 256], embedding_size=32):\n",
    "        super().__init__()\n",
    "        self.enc_layers = th.nn.ModuleList()\n",
    "        prev_units = inp_size\n",
    "        for units in encoding:\n",
    "            self.enc_layers.append(th.nn.Linear(prev_units, units))\n",
    "            self.enc_layers.append(th.nn.ReLU())\n",
    "            prev_units = units\n",
    "        \n",
    "        # Here the stuff gets a bit more complicated than `self.embedding = th.nn.Linear(prev_units, embedding_size)`\n",
    "\n",
    "        prev_units = embedding_size\n",
    "        self.dec_layers = th.nn.ModuleList()\n",
    "        for units in reversed(encoding):\n",
    "            self.dec_layers.append(th.nn.Linear(prev_units, units))\n",
    "            prev_units = units\n",
    "            self.dec_layers.append(th.nn.ReLU())\n",
    "        \n",
    "        self.readout = th.nn.Linear(prev_units, inp_size)\n",
    "        return\n",
    "        \n",
    "    def encoder(self, inputs):\n",
    "        if len(inputs.shape) > 2: \n",
    "            # do NOT use this approach in real-life models.\n",
    "            # instead use pre-processing reshaping (via tv pre-proc pipeline or manual)\n",
    "            th_x = inputs.view(inputs.shape[0], -1)\n",
    "        else:\n",
    "            th_x = inputs\n",
    "            \n",
    "        for layer in self.enc_layers:\n",
    "            th_x = layer(th_x)\n",
    "        return self.embedding(th_x)\n",
    "    \n",
    "    def decoder(self, inputs):\n",
    "        th_x = inputs\n",
    "        for layer in self.dec_layers:\n",
    "            th_x = layer(th_x)\n",
    "        return self.readout(th_x)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        th_x = self.encoder(inputs)\n",
    "        th_x = None # again the stuff gets a bit complicated\n",
    "        th_x = self.decoder(th_x)\n",
    "        \n",
    "model = SimpleAutoEncoder(28*28).cuda()\n",
    "model        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
